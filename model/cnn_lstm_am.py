# -*- coding: utf-8 -*-
"""CNN-LSTM-AM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WPb4f28VXPtqd2DYF0V0pNsJhVLMCvSF
"""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

!pip install numpy==1.19.5

#!pip install keras-tcn

!pip install tensorflow==2.1.0
#!pip install keras --upgrade



import tensorflow as tf
print(tf.__version__)

#!pip install tensorflow-estimator==2.1.0

#!pip install tensorflow-addons

## keras
from tcn import TCN
from tensorflow_core.python.keras import Input, Model
from tensorflow_core.python.keras.layers import Dropout, Dense, Attention, RepeatVector, LSTM, CuDNNLSTM, Conv1D, MaxPooling1D, \
    Flatten

df=pd.read_csv('https://raw.githubusercontent.com/herecomesmax/herecomesmax/data/datas.csv',index_col=0)

# PUT THE CLOSE PRICE THE THE FIRST COLUMN
col=df.columns[[1,0,2,3,4]]
df=df[col]
df.head()

# TRANSFORM THE DATA TO AN ARRAY, AND SPLIT TRAINING/TESTING DATA
values = df.values
X=values[:,1:5]
Y=values[:,0].reshape(-1,1)
y_len=len(Y)
test_len=458
tran_len=y_len-test_len

# SHOW TRAINING DATA
aa = [x for x in range(tran_len)]
plt.plot(aa, Y[:tran_len])
plt.ylabel('colse', size=15)
plt.xlabel('Time', size=15)
plt.legend(fontsize=15)
plt.show()

# SHOW TESTING DATA
aa = [x for x in range(test_len)]
plt.plot(aa, Y[tran_len:])
plt.ylabel('close', size=15)
plt.xlabel('Time', size=15)
plt.legend(fontsize=15)
plt.show()

# X,Y STANDARDIZATION
from sklearn.preprocessing import MinMaxScaler

scX = MinMaxScaler(feature_range=(0, 1))
scY = MinMaxScaler(feature_range=(0, 1))

scaledX = scX.fit_transform(X)
scaledY = scY.fit_transform(Y)

data=np.concatenate((scaledX, scaledY), axis=1)

data_train=data[:tran_len,:]
data_test=data[tran_len:,:]

seq_len = 5  # TIME STEP t-5,t-4,t-3,t-2,t-1 --->t
# TRANSFORM TO LSTM DATA FORM (SAMPLE, TIME STEP, FEATURES)
X_train = np.array([data_train[i : i + seq_len, 0:4] for i in range(data_train.shape[0] - seq_len)])
y_train = np.array([data_train[i + seq_len, 4] for i in range(data_train.shape[0]- seq_len)])
X_test = np.array([data_test[i : i + seq_len, 0:4] for i in range(data_test.shape[0]- seq_len)])
y_test = np.array([data_test[i + seq_len, 4] for i in range(data_test.shape[0] - seq_len)])

print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

# KERAS MODEL
# PLEASE CONDUCT MORE EXPERIMENTS AND FIND THE BEST PARAMETER
inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))  
cnn1 =Conv1D(filters=10,kernel_size=32, padding='same', strides=1, activation='relu',input_shape=(X_train.shape[1], X_train.shape[2]))(inputs)
cnn2 =Conv1D(filters=10,kernel_size=64, padding='same', strides=1, activation='relu',input_shape=(X_train.shape[1], X_train.shape[2]))(cnn1)
mp=MaxPooling1D(pool_size=1,strides=1)(cnn2)
ft=Flatten()(mp)
rp=RepeatVector(30)(ft)
lt=LSTM(100)(rp)
# I ADDED THIS ATTENTION LAYER, BUT THE RESULT TURNED OUT NOT SO GOOD. FURTHER INVESTIGATIONS ARE REQUIRED SO PLEASE...
#attention_layer=Attention()([lt,lt])
#dp=Dropout(0.2)(attention_layer)
out_layer = Dense(1, activation='linear')(lt)  #
model = Model(inputs=inputs, outputs=out_layer)
model.compile(optimizer='adam', loss='mean_squared_error')
# fit network
history = model.fit(X_train, y_train, epochs=100, batch_size=70, validation_data=(X_test, y_test), verbose=2, shuffle=False)

# SHOW THE TRAINING LOSS
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

# PREDICTION
yhat = model.predict(X_test)
# RESTORATION Y-HAT
inv_yhat = scY.inverse_transform(yhat)
# RESTORATION Y-TEST
inv_y = scY.inverse_transform(y_test.reshape(-1,1))

# METRICS CALCULATION
rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))
print('Test RMSE: %.3f' % rmse)
mse=mean_squared_error(inv_y, inv_yhat)
print('Test MSE: %.3f' % mse)

aa = [x for x in range(len(y_test))]
plt.plot(aa, inv_y[:len(y_test)], label="actual")
plt.plot(aa, inv_yhat[:len(y_test)], 'r', label="prediction")
plt.ylabel('predict', size=15)
plt.xlabel('Time', size=15)
plt.legend(fontsize=15)
plt.show()
