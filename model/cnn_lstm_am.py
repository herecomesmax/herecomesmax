# -*- coding: utf-8 -*-
"""CNN-LSTM-AM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WPb4f28VXPtqd2DYF0V0pNsJhVLMCvSF
"""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

!pip install numpy==1.19.5

#!pip install keras-tcn

!pip install tensorflow==2.1.0
#!pip install keras --upgrade



import tensorflow as tf
print(tf.__version__)

#!pip install tensorflow-estimator==2.1.0

#!pip install tensorflow-addons

## keras
from tcn import TCN
from tensorflow_core.python.keras import Input, Model
from tensorflow_core.python.keras.layers import Dropout, Dense, Attention, RepeatVector, LSTM, CuDNNLSTM, Conv1D, MaxPooling1D, \
    Flatten

df=pd.read_csv('https://raw.githubusercontent.com/herecomesmax/herecomesmax/data/datas.csv',index_col=0)
#把close即收盘价放到第一列
col=df.columns[[1,0,2,3,4]]
df=df[col]
df.head()

#把数据转为array类型，并划分训练集和测试集长度
values = df.values
X=values[:,1:5]
Y=values[:,0].reshape(-1,1)
y_len=len(Y)
test_len=458
tran_len=y_len-test_len

#显示训练数据
aa = [x for x in range(tran_len)]
plt.plot(aa, Y[:tran_len])
plt.ylabel('colse', size=15)
plt.xlabel('Time', size=15)
plt.legend(fontsize=15)
plt.show()

#显示测试集的数据
aa = [x for x in range(test_len)]
plt.plot(aa, Y[tran_len:])
plt.ylabel('close', size=15)
plt.xlabel('Time', size=15)
plt.legend(fontsize=15)
plt.show()

#对X和y分别进行归一化
from sklearn.preprocessing import MinMaxScaler

scX = MinMaxScaler(feature_range=(0, 1))
scY = MinMaxScaler(feature_range=(0, 1))

scaledX = scX.fit_transform(X)
scaledY = scY.fit_transform(Y)

data=np.concatenate((scaledX, scaledY), axis=1)

data_train=data[:tran_len,:]
data_test=data[tran_len:,:]

seq_len = 5  #时间步长 t-5,t-4,t-3,t-2,t-1 --->t
#转换成LSTM所需格式，（样本数，步长，特征数）
X_train = np.array([data_train[i : i + seq_len, 0:4] for i in range(data_train.shape[0] - seq_len)])
y_train = np.array([data_train[i + seq_len, 4] for i in range(data_train.shape[0]- seq_len)])
X_test = np.array([data_test[i : i + seq_len, 0:4] for i in range(data_test.shape[0]- seq_len)])
y_test = np.array([data_test[i + seq_len, 4] for i in range(data_test.shape[0] - seq_len)])

print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

#网络模型keras
#网络结构模型训练次数和参数等都不是最优的，需要自己结合自己数据来调
inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))  # 构建输入的大小，即张量
cnn1 =Conv1D(filters=10,kernel_size=32, padding='same', strides=1, activation='relu',input_shape=(X_train.shape[1], X_train.shape[2]))(inputs)
cnn2 =Conv1D(filters=10,kernel_size=64, padding='same', strides=1, activation='relu',input_shape=(X_train.shape[1], X_train.shape[2]))(cnn1)
mp=MaxPooling1D(pool_size=1,strides=1)(cnn2)
ft=Flatten()(mp)
rp=RepeatVector(30)(ft)
lt=LSTM(100)(rp)
#attention_layer=Attention()([lt,lt])
#dp=Dropout(0.2)(attention_layer)
out_layer = Dense(1, activation='linear')(lt)  #
model = Model(inputs=inputs, outputs=out_layer)
model.compile(optimizer='adam', loss='mean_squared_error')
# fit network
history = model.fit(X_train, y_train, epochs=100, batch_size=70, validation_data=(X_test, y_test), verbose=2, shuffle=False)

# 显示训练的loss值情况
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()

# 做预测
yhat = model.predict(X_test)
#反归一化预测值
inv_yhat = scY.inverse_transform(yhat)
# 反归一化真实值
inv_y = scY.inverse_transform(y_test.reshape(-1,1))

# 计算 RMSE
rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))
print('Test RMSE: %.3f' % rmse)
mse=mean_squared_error(inv_y, inv_yhat)
print('Test MSE: %.3f' % mse)

aa = [x for x in range(len(y_test))]
plt.plot(aa, inv_y[:len(y_test)], label="actual")
plt.plot(aa, inv_yhat[:len(y_test)], 'r', label="prediction")
plt.ylabel('predict', size=15)
plt.xlabel('Time', size=15)
plt.legend(fontsize=15)
plt.show()